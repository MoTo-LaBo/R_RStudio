---
title: "回帰直線"
output: html_notebook
---

#### regression line

### 回帰直線

- data の裏にある隠された法則を見つる
  
  - 二次元の data に当てはめ　→　**線形回帰直線**　→　**予測 data の取得**


|営業所|広告費<br>(万円)|売上<br>(万円)|
|:-:|:-:|:-:|
|A|12.5|141|
|B|20.2|188|
|C|11.1|111|
|D|18.2|150|
|E|19.9|156|
|F|14.3|154|

$$
y　=　bx + a
$$
<center>
<br>
↓<br>
<br>
手持ちのdataで　<b><font color = "red">傾き・切片</font></b>　を求める<br>
<br>
↓<br>
<br>
<h4><b><font color = "red">予測 data 取得</font></b></h4>
</center>

### 最小二乗法

- **誤差が二乗の総和**　が最小になる様な直線を見つける

|値|公式|
|:-:|:-:|
|**実際の値**|$y_i$|
|**直線上の値**|$\hat{y_i} = bx_i + a$|
|**誤差**|$e_i = y_i - (bx_i + a)$|
|**誤差の二乗の総和**|$\sum e^2_i$|

#### 公式

$$
b　=　\frac{共分散}{xの分散} \\
\\
\\
a　=　yの\mu　-　b　\times　xの\mu
$$
#### 回帰直線の特徴

- **決定係数** $r^2$ : 求めた回帰直線の　**当てはまりの良さ**　を表す値

  →　相関係数　$r$　の二乗 0 $\leqq$　$r$　$\leqq$ 1　→　１に近いほど当てはまりが良い
  

<center>
<br>
y の変動数<br>
<br>
||<br>
<br>
<b><font color = "red">回帰直線　+　残差</font></b><br>
<br>
↓<br>
<br>
<h4><b><font color = "red">回帰直線の説明力</font></b></h4><br>
<br>
</center>

#### 因果関係

- **回帰分析でも因果関係の有無に注意**

  - **原因**
    - 説明変数, 独立変数
    
  - **結果**
    - 被説明変数, 従属変数

$$
原因(x)　＝　結果(y) \\
\\
結果(y)　\neq　原因(x)
$$
#### cars data

- 車の speed(速さ): x軸　と　dist(制動距離): y軸　の関係

  - **相関係数** : `r cor(x, y)`
```{r}
cars

x <- cars$speed
y <- cars$dist

plot(x, y)
cor(x, y)
```

### 線形回帰直線を求めて plot

- 誤差が最小になる値の直線を引く

  - **傾き** : `r b`

  - **切片** : `r a`

```{r}
b <- cov(x, y) / var(x)
a <- mean(y) - b*mean(x) 
c(b, a)

plot(x, y)
abline(a, b)
```

#### 線形回帰直線

- R言語の関数
  ```
  lm(目的変数 ~ 説明変数)
  ```
```{r}
res <- lm(y ~ x)
plot(x, y)
abline(res)
```

***

## 重回帰分析

- 説明変数が(原因)が2つ以上の回帰分析

  - 変数が1つの時は　**直線**　→　2つの時は **平面**　を当てはめる
  
  
<center>
<br>
重回帰分析<br>
<br>
||<br>
<br>
<b><font color = "red">１つの結果に対して...</font></b><br>
<br>
↓<br>
<br>
<h4><b><font color = "red">複数の原因がある</font></b></h4><br>
<br>
</center>

$$
y　=　a + b_1x_1 + b_2x_2
$$

  - $a,　b_1,　b_2$　を求めると式が決定

### 公式
#### 重回帰分析 paramerter

$$
\sum e^2_i　=　\{y_i - (a + b_1x_1 + b_2x_2)\}^2
$$
- 最小になる a, b1, b2 を求めるのだが... -> 難しいので pc に任せよう！

***

#### 標準回帰係数

- あらかじめ説明変数を　**標準化**　することで比較が可能になる

  - **scale**　を合わせる事により, category が違うものを比較可能に出来る
  
    - 広告費, 人員数, 販売個数 etc...

$$
標準化　=　\frac{X - \mu}{\sigma}
$$

- **各値** : $X$

- **平均** : $\mu$

- **標準偏差** : $\sigma$

***

#### 重回帰分析を計算

- R　で計算

```
lm(目的変数 ~ 説明変数1, 説明変数2,...)
```

```{r}
y1 <- c(82, 97, 130, 108, 144, 165)
x1 <- c(11, 10, 14, 9, 15, 20)
x2 <- c(3, 4, 5, 7, 6, 7)

res1 <- lm(y1~x1+x2)
res1
```

#### 標準化して重回帰分析

```{r}
ys <- scale(y1)
xs1 <- scale(x1)
xs2 <- scale(x2)

res2 <- lm(ys~xs1+xs2)
res2
```
***

## 重回帰分析の注意点

<center>
<br>
説明変数はなるべく　<b><font color = "red">独立</font></b>　になる様に<br>
<br>
↓<br>
<br>
<b><font color = "red">多重共線性</font></b>
<br>
↓<br>
<br>
相関係数を使用して　<b><font color = "red">説明変数</font></b>　の確認<br>
<br>
↓<br>
<br>
<b><font color = "red">同じような変数は 1 に近くなる</font></b><br>
<br>
</center>

#### 説明変数は多いほど良いのか?
<center>
<br>
<br>
関係が薄い項目があると　<b><font color = "red">重回帰分析の当てはまりが悪くなる</font></b><br>
<br>
↓<br>
<br>
<br>
相関係数を使用して　<b><font color = "red">説明変数</font></b>　の確認<br>
<br>
↓<br>
<br>
<b><font color = "red">当てはまりが悪い変数は 0 に近くなる</font></b><br>
<br>
↓<br>
<br>
目的変数と相関関係に着目して　<b><font color = "red">相関係数が低い項目は削除</font></b><br>
<br>
</center>

